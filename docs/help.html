<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>HOWARD Help</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 1000px;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">HOWARD Help</h1>
</header>
<nav id="TOC" role="doc-toc">
<h2 id="toc-title">Contents</h2>
<ul>
<li><a href="#introduction" id="toc-introduction"><span
class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#query-tool" id="toc-query-tool"><span
class="toc-section-number">2</span> QUERY tool</a>
<ul>
<li><a href="#main-options" id="toc-main-options"><span
class="toc-section-number">2.1</span> Main options</a></li>
<li><a href="#explode" id="toc-explode"><span
class="toc-section-number">2.2</span> Explode</a></li>
<li><a href="#query" id="toc-query"><span
class="toc-section-number">2.3</span> Query</a></li>
<li><a href="#export" id="toc-export"><span
class="toc-section-number">2.4</span> Export</a></li>
</ul></li>
<li><a href="#stats-tool" id="toc-stats-tool"><span
class="toc-section-number">3</span> STATS tool</a>
<ul>
<li><a href="#main-options-1" id="toc-main-options-1"><span
class="toc-section-number">3.1</span> Main options</a></li>
<li><a href="#stats" id="toc-stats"><span
class="toc-section-number">3.2</span> Stats</a></li>
</ul></li>
<li><a href="#convert-tool" id="toc-convert-tool"><span
class="toc-section-number">4</span> CONVERT tool</a>
<ul>
<li><a href="#main-options-2" id="toc-main-options-2"><span
class="toc-section-number">4.1</span> Main options</a></li>
<li><a href="#explode-1" id="toc-explode-1"><span
class="toc-section-number">4.2</span> Explode</a></li>
<li><a href="#export-1" id="toc-export-1"><span
class="toc-section-number">4.3</span> Export</a></li>
</ul></li>
<li><a href="#hgvs-tool" id="toc-hgvs-tool"><span
class="toc-section-number">5</span> HGVS tool</a>
<ul>
<li><a href="#main-options-3" id="toc-main-options-3"><span
class="toc-section-number">5.1</span> Main options</a></li>
<li><a href="#hgvs" id="toc-hgvs"><span
class="toc-section-number">5.2</span> HGVS</a></li>
</ul></li>
<li><a href="#annotation-tool" id="toc-annotation-tool"><span
class="toc-section-number">6</span> ANNOTATION tool</a>
<ul>
<li><a href="#main-options-4" id="toc-main-options-4"><span
class="toc-section-number">6.1</span> Main options</a></li>
<li><a href="#annotation" id="toc-annotation"><span
class="toc-section-number">6.2</span> Annotation</a></li>
</ul></li>
<li><a href="#calculation-tool" id="toc-calculation-tool"><span
class="toc-section-number">7</span> CALCULATION tool</a>
<ul>
<li><a href="#main-options-5" id="toc-main-options-5"><span
class="toc-section-number">7.1</span> Main options</a></li>
<li><a href="#calculation" id="toc-calculation"><span
class="toc-section-number">7.2</span> Calculation</a></li>
<li><a href="#nomen" id="toc-nomen"><span
class="toc-section-number">7.3</span> NOMEN</a></li>
<li><a href="#trio" id="toc-trio"><span
class="toc-section-number">7.4</span> TRIO</a></li>
<li><a href="#barcodefamily" id="toc-barcodefamily"><span
class="toc-section-number">7.5</span> BARCODEFAMILY</a></li>
</ul></li>
<li><a href="#prioritization-tool" id="toc-prioritization-tool"><span
class="toc-section-number">8</span> PRIORITIZATION tool</a>
<ul>
<li><a href="#main-options-6" id="toc-main-options-6"><span
class="toc-section-number">8.1</span> Main options</a></li>
<li><a href="#prioritization" id="toc-prioritization"><span
class="toc-section-number">8.2</span> Prioritization</a></li>
</ul></li>
<li><a href="#process-tool" id="toc-process-tool"><span
class="toc-section-number">9</span> PROCESS tool</a>
<ul>
<li><a href="#main-options-7" id="toc-main-options-7"><span
class="toc-section-number">9.1</span> Main options</a></li>
<li><a href="#hgvs-1" id="toc-hgvs-1"><span
class="toc-section-number">9.2</span> HGVS</a></li>
<li><a href="#annotation-1" id="toc-annotation-1"><span
class="toc-section-number">9.3</span> Annotation</a></li>
<li><a href="#calculation-1" id="toc-calculation-1"><span
class="toc-section-number">9.4</span> Calculation</a></li>
<li><a href="#prioritization-1" id="toc-prioritization-1"><span
class="toc-section-number">9.5</span> Prioritization</a></li>
<li><a href="#query-1" id="toc-query-1"><span
class="toc-section-number">9.6</span> Query</a></li>
<li><a href="#explode-2" id="toc-explode-2"><span
class="toc-section-number">9.7</span> Explode</a></li>
<li><a href="#export-2" id="toc-export-2"><span
class="toc-section-number">9.8</span> Export</a></li>
</ul></li>
<li><a href="#databases-tool" id="toc-databases-tool"><span
class="toc-section-number">10</span> DATABASES tool</a>
<ul>
<li><a href="#main-options-8" id="toc-main-options-8"><span
class="toc-section-number">10.1</span> Main options</a></li>
<li><a href="#genomes" id="toc-genomes"><span
class="toc-section-number">10.2</span> Genomes</a></li>
<li><a href="#snpeff" id="toc-snpeff"><span
class="toc-section-number">10.3</span> snpEff</a></li>
<li><a href="#annovar" id="toc-annovar"><span
class="toc-section-number">10.4</span> Annovar</a></li>
<li><a href="#refseq" id="toc-refseq"><span
class="toc-section-number">10.5</span> refSeq</a></li>
<li><a href="#dbnsfp" id="toc-dbnsfp"><span
class="toc-section-number">10.6</span> dbNSFP</a></li>
<li><a href="#alphamissense" id="toc-alphamissense"><span
class="toc-section-number">10.7</span> AlphaMissense</a></li>
<li><a href="#exomiser" id="toc-exomiser"><span
class="toc-section-number">10.8</span> Exomiser</a></li>
<li><a href="#dbsnp" id="toc-dbsnp"><span
class="toc-section-number">10.9</span> dbSNP</a></li>
<li><a href="#hgmd" id="toc-hgmd"><span
class="toc-section-number">10.10</span> HGMD</a></li>
<li><a href="#from_annovar" id="toc-from_annovar"><span
class="toc-section-number">10.11</span> from_Annovar</a></li>
<li><a href="#from_extann" id="toc-from_extann"><span
class="toc-section-number">10.12</span> from_extann</a></li>
<li><a href="#parameters" id="toc-parameters"><span
class="toc-section-number">10.13</span> Parameters</a></li>
</ul></li>
<li><a href="#gui-tool" id="toc-gui-tool"><span
class="toc-section-number">11</span> GUI tool</a></li>
<li><a href="#help-tool" id="toc-help-tool"><span
class="toc-section-number">12</span> HELP tool</a>
<ul>
<li><a href="#main-options-9" id="toc-main-options-9"><span
class="toc-section-number">12.1</span> Main options</a></li>
</ul></li>
<li><a href="#update_database-tool" id="toc-update_database-tool"><span
class="toc-section-number">13</span> UPDATE_DATABASE tool</a>
<ul>
<li><a href="#main-options-10" id="toc-main-options-10"><span
class="toc-section-number">13.1</span> Main options</a></li>
<li><a href="#update_database" id="toc-update_database"><span
class="toc-section-number">13.2</span> Update_database</a></li>
<li><a href="#options" id="toc-options"><span
class="toc-section-number">13.3</span> Options</a></li>
</ul></li>
<li><a href="#transcripts_check-tool"
id="toc-transcripts_check-tool"><span
class="toc-section-number">14</span> TRANSCRIPTS_CHECK tool</a>
<ul>
<li><a href="#main-options-11" id="toc-main-options-11"><span
class="toc-section-number">14.1</span> Main options</a></li>
</ul></li>
<li><a href="#genebe-tool" id="toc-genebe-tool"><span
class="toc-section-number">15</span> GENEBE tool</a>
<ul>
<li><a href="#main-options-12" id="toc-main-options-12"><span
class="toc-section-number">15.1</span> Main options</a></li>
<li><a href="#genebe" id="toc-genebe"><span
class="toc-section-number">15.2</span> GeneBe</a></li>
<li><a href="#explode-3" id="toc-explode-3"><span
class="toc-section-number">15.3</span> Explode</a></li>
<li><a href="#export-3" id="toc-export-3"><span
class="toc-section-number">15.4</span> Export</a></li>
</ul></li>
<li><a href="#minimalize-tool" id="toc-minimalize-tool"><span
class="toc-section-number">16</span> MINIMALIZE tool</a>
<ul>
<li><a href="#main-options-13" id="toc-main-options-13"><span
class="toc-section-number">16.1</span> Main options</a></li>
<li><a href="#minimalize" id="toc-minimalize"><span
class="toc-section-number">16.2</span> Minimalize</a></li>
<li><a href="#explode-4" id="toc-explode-4"><span
class="toc-section-number">16.3</span> Explode</a></li>
<li><a href="#export-4" id="toc-export-4"><span
class="toc-section-number">16.4</span> Export</a></li>
</ul></li>
<li><a href="#shared-arguments" id="toc-shared-arguments"><span
class="toc-section-number">17</span> Shared arguments</a></li>
</ul>
</nav>
<h1 data-number="1" id="introduction"><span
class="header-section-number">1</span> Introduction</h1>
<!--TOC-->
<p>HOWARD:0.11.0</p>
<p>Highly Open Workflow for Annotation &amp; Ranking toward genomic
variant Discovery</p>
<p>HOWARD annotates and prioritizes genetic variations, calculates and
normalizes annotations, convert on multiple formats, query variations
and generates statistics</p>
<p>Usage examples:</p>
<blockquote>
<p>howard process &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.annotated.vcf.gz &#x2013;param=config/param.json</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.vcf.gz
&#x2013;annotations=&#x2018;tests/databases/annotations/current/hg19/dbnsfp42a.parquet,tests/databases/annotations/current/hg19/gnomad211_genome.parquet&#x2019;</p>
</blockquote>
<blockquote>
<p>howard calculation &#x2013;input=tests/data/example.full.vcf
&#x2013;output=/tmp/example.calculation.tsv &#x2013;calculations=&#x2018;vartype&#x2019;</p>
</blockquote>
<blockquote>
<p>howard prioritization &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.prioritized.vcf.gz
&#x2013;prioritization_config=config/prioritization_profiles.json
&#x2013;prioritizations=&#x2018;default,GERMLINE&#x2019;</p>
</blockquote>
<blockquote>
<p>howard query &#x2013;input=tests/data/example.vcf.gz &#x2013;explode_infos
&#x2013;query=&#x2018;SELECT &#x201C;#CHROM&#x201D;, POS, REF, ALT, &#x201C;DP&#x201D;, &#x201C;CLNSIG&#x201D;, sample2, sample3
FROM variants WHERE &#x201C;DP&#x201D; &gt;= 50 OR &#x201C;CLNSIG&#x201D; NOT NULL ORDER BY &#x201C;CLNSIG&#x201D;
DESC, &#x201C;DP&#x201D; DESC&#x2019;</p>
</blockquote>
<blockquote>
<p>howard stats &#x2013;input=tests/data/example.vcf.gz</p>
</blockquote>
<blockquote>
<p>howard convert &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.tsv &#x2013;explode_infos &amp;&amp; cat
/tmp/example.tsv</p>
</blockquote>
<h1 data-number="2" id="query-tool"><span
class="header-section-number">2</span> QUERY tool</h1>
<p>Query genetic variations in SQL format. Data can be loaded into
&#x2018;variants&#x2019; table from various formats (e.g.&#xA0;VCF, TSV, Parquet&#x2026;). Using
&#x2013;explode_infos allow query on INFO/tag annotations. SQL query can also
use external data within the request, such as a Parquet file(s).</p>
<p>Usage examples:</p>
<blockquote>
<p>howard query &#x2013;input=tests/data/example.vcf.gz &#x2013;query=&#x201C;SELECT * FROM
variants WHERE REF = &#x2018;A&#x2019; AND POS &lt; 100000&#x201D;</p>
</blockquote>
<blockquote>
<p>howard query &#x2013;input=tests/data/example.vcf.gz &#x2013;explode_infos
&#x2013;query=&#x2018;SELECT &#x201C;#CHROM&#x201D;, POS, REF, ALT, DP, CLNSIG, sample2, sample3
FROM variants WHERE DP &gt;= 50 OR CLNSIG NOT NULL ORDER BY DP DESC&#x2019;</p>
</blockquote>
<blockquote>
<p>howard query &#x2013;query=&#x201C;SELECT "#CHROM", POS, REF, ALT,
"INFO/Interpro_domain" FROM
&#x2018;tests/databases/annotations/current/hg19/dbnsfp42a.parquet&#x2019; WHERE
"INFO/Interpro_domain" NOT NULL ORDER BY
"INFO/SiPhy_29way_logOdds_rankscore" DESC LIMIT 10&#x201D;</p>
</blockquote>
<blockquote>
<p>howard query &#x2013;explode_infos &#x2013;explode_infos_prefix=&#x2018;INFO/&#x2019;
&#x2013;query=&#x201C;SELECT "#CHROM", POS, REF, ALT, STRING_AGG(INFO, &#x2018;;&#x2019;) AS INFO
FROM &#x2019;tests/databases/annotations/current/hg19/*.parquet&#x2019; GROUP BY
"#CHROM", POS, REF, ALT&#x201D; &#x2013;output=/tmp/full_annotation.tsv &amp;&amp;
head -n2 /tmp/full_annotation.tsv</p>
</blockquote>
<blockquote>
<p>howard query &#x2013;input=tests/data/example.vcf.gz
&#x2013;param=config/param.json</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="2.1" id="main-options"><span
class="header-section-number">2.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt;

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output=&lt;output&gt;

Output file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--query=&lt;query&gt;

Query in SQL format
(e.g. &#39;SELECT * FROM variants LIMIT 50&#39;).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="2.2" id="explode"><span
class="header-section-number">2.2</span> Explode</h2>
<p><small></p>
<blockquote>
<pre><code>--explode_infos

Explode VCF INFO/Tag into &#39;variants&#39; table columns.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_prefix=&lt;explode infos prefix&gt;

Explode VCF INFO/Tag with a specific prefix.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_fields=&lt;explode infos list&gt; (default: *)

Explode VCF INFO/Tag specific fields/tags.
Keyword `*` specify all available fields, except those already specified.
Pattern (regex) can be used, such as `.*_score` for fields named with &#39;_score&#39; at the end.
Examples:
- &#39;HGVS,SIFT,Clinvar&#39; (list of fields)
- &#39;HGVS,*,Clinvar&#39; (list of fields with all other fields at the end)
- &#39;HGVS,.*_score,Clinvar&#39; (list of 2 fields with all scores in the middle)
- &#39;HGVS,.*_score,*&#39; (1 field, scores, all other fields)
- &#39;HGVS,*,.*_score&#39; (1 field, all other fields, all scores)</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="2.3" id="query"><span
class="header-section-number">2.3</span> Query</h2>
<p><small></p>
<blockquote>
<pre><code>--query_limit=&lt;query limit&gt; (default: 10)

Limit of number of row for query (only for print result, not output).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--query_print_mode=&lt;print mode&gt; [None, &#39;markdown&#39;, &#39;tabulate&#39;, &#39;disabled&#39;]

Print mode of query result (only for print result, not output).
Either None (native), &#39;markdown&#39;, &#39;tabulate&#39; or disabled.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="2.4" id="export"><span
class="header-section-number">2.4</span> Export</h2>
<p><small></p>
<blockquote>
<pre><code>--include_header

Include header (in VCF format) in output file.
Only for compatible formats (tab-delimiter format as TSV or BED).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--parquet_partitions=&lt;parquet partitions&gt;

Parquet partitioning using hive (available for any format).
This option is faster parallel writing, but memory consuming.
Use &#39;None&#39; (string) for NO partition but split parquet files into a folder.
Examples: &#39;#CHROM&#39;, &#39;#CHROM,REF&#39;, &#39;None&#39;.</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="3" id="stats-tool"><span
class="header-section-number">3</span> STATS tool</h1>
<p>Statistics on genetic variations, such as: number of variants, number
of samples, statistics by chromosome, genotypes by samples&#x2026;</p>
<p>Usage examples:</p>
<blockquote>
<p>howard stats &#x2013;input=tests/data/example.vcf.gz</p>
</blockquote>
<blockquote>
<p>howard stats &#x2013;input=tests/data/example.vcf.gz
&#x2013;stats_md=/tmp/stats.md</p>
</blockquote>
<blockquote>
<p>howard stats &#x2013;input=tests/data/example.vcf.gz
&#x2013;param=config/param.json</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="3.1" id="main-options-1"><span
class="header-section-number">3.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt; | required

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="3.2" id="stats"><span
class="header-section-number">3.2</span> Stats</h2>
<p><small></p>
<blockquote>
<pre><code>--stats_md=&lt;stats markdown&gt;

Stats Output file in MarkDown format.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--stats_json=&lt;stats json&gt;

Stats Output file in JSON format.</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="4" id="convert-tool"><span
class="header-section-number">4</span> CONVERT tool</h1>
<p>Convert genetic variations file to another format. Multiple format
are available, such as usual and official VCF and BCF format, but also
other formats such as TSV, CSV, PSV and Parquet/duckDB. These formats
need a header &#x2018;.hdr&#x2019; file to take advantage of the power of howard
(especially through INFO/tag definition), and using howard convert tool
automatically generate header file fo futher use.</p>
<p>Usage examples:</p>
<blockquote>
<p>howard convert &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.tsv</p>
</blockquote>
<blockquote>
<p>howard convert &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.parquet</p>
</blockquote>
<blockquote>
<p>howard convert &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.tsv &#x2013;explode_infos
&#x2013;explode_infos_fields=&#x2018;CLNSIG,SIFT,DP&#x2019; &#x2013;order_by=&#x2018;CLNSIG DESC, DP
DESC&#x2019;</p>
</blockquote>
<blockquote>
<p>howard convert &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.tsv &#x2013;explode_infos &#x2013;explode_infos_prefix=&#x2018;INFO/&#x2019;
&#x2013;explode_infos_fields=&#x2019;CLNSIG,SIFT,DP,*&#x2019; &#x2013;order_by=&#x2018;&#x201C;INFO/CLNSIG&#x201D; DESC,
&#x201C;INFO/DP&#x201D; DESC&#x2019; &#x2013;include_header</p>
</blockquote>
<blockquote>
<p>howard convert &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.tsv &#x2013;param=config/param.json</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="4.1" id="main-options-2"><span
class="header-section-number">4.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt; | required

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output=&lt;output&gt; | required

Output file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="4.2" id="explode-1"><span
class="header-section-number">4.2</span> Explode</h2>
<p><small></p>
<blockquote>
<pre><code>--explode_infos

Explode VCF INFO/Tag into &#39;variants&#39; table columns.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_prefix=&lt;explode infos prefix&gt;

Explode VCF INFO/Tag with a specific prefix.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_fields=&lt;explode infos list&gt; (default: *)

Explode VCF INFO/Tag specific fields/tags.
Keyword `*` specify all available fields, except those already specified.
Pattern (regex) can be used, such as `.*_score` for fields named with &#39;_score&#39; at the end.
Examples:
- &#39;HGVS,SIFT,Clinvar&#39; (list of fields)
- &#39;HGVS,*,Clinvar&#39; (list of fields with all other fields at the end)
- &#39;HGVS,.*_score,Clinvar&#39; (list of 2 fields with all scores in the middle)
- &#39;HGVS,.*_score,*&#39; (1 field, scores, all other fields)
- &#39;HGVS,*,.*_score&#39; (1 field, all other fields, all scores)</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="4.3" id="export-1"><span
class="header-section-number">4.3</span> Export</h2>
<p><small></p>
<blockquote>
<pre><code>--include_header

Include header (in VCF format) in output file.
Only for compatible formats (tab-delimiter format as TSV or BED).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--order_by=&lt;order by&gt;

List of columns to sort the result-set in ascending or descending order.
Use SQL format, and keywords ASC (ascending) and DESC (descending).
If a column is not available, order will not be considered.
Order is enable only for compatible format (e.g. TSV, CSV, JSON).
Examples: &#39;ACMG_score DESC&#39;, &#39;PZFlag DESC, PZScore DESC&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--parquet_partitions=&lt;parquet partitions&gt;

Parquet partitioning using hive (available for any format).
This option is faster parallel writing, but memory consuming.
Use &#39;None&#39; (string) for NO partition but split parquet files into a folder.
Examples: &#39;#CHROM&#39;, &#39;#CHROM,REF&#39;, &#39;None&#39;.</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="5" id="hgvs-tool"><span
class="header-section-number">5</span> HGVS tool</h1>
<p>HGVS annotation using HUGO HGVS internation Sequence Variant
Nomenclature (http://varnomen.hgvs.org/). Annotation refere to refGene
and genome to generate HGVS nomenclature for all available transcripts.
This annotation add &#x2018;hgvs&#x2019; field into VCF INFO column of a VCF file.</p>
<p>Usage examples:</p>
<blockquote>
<p>howard hgvs &#x2013;input=tests/data/example.full.vcf
&#x2013;output=/tmp/example.hgvs.vcf</p>
</blockquote>
<blockquote>
<p>howard hgvs &#x2013;input=tests/data/example.full.vcf
&#x2013;output=/tmp/example.hgvs.tsv &#x2013;param=config/param.json</p>
</blockquote>
<blockquote>
<p>howard hgvs &#x2013;input=tests/data/example.full.vcf
&#x2013;output=/tmp/example.hgvs.vcf &#x2013;full_format &#x2013;use_exon</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="5.1" id="main-options-3"><span
class="header-section-number">5.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt; | required

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output=&lt;output&gt; | required

Output file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--hgvs_options=&lt;HGVS options&gt;

Quick HGVS annotation options.
This option will skip all other hgvs options.
Examples:
- &#39;default&#39; (for default options)
- &#39;full_format&#39; (for full format HGVS annotation)
- &#39;use_gene=True:add_protein=true:codon_type=FULL&#39;</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--assembly=&lt;assembly&gt; (default: hg19)

Genome Assembly (e.g. &#39;hg19&#39;, &#39;hg38&#39;).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="5.2" id="hgvs"><span
class="header-section-number">5.2</span> HGVS</h2>
<p><small></p>
<blockquote>
<pre><code>--use_gene

Use Gene information to generate HGVS annotation
(e.g. &#39;NM_152232(TAS1R2):c.231T&gt;C&#39;)</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--use_exon

Use Exon information to generate HGVS annotation
(e.g. &#39;NM_152232(exon2):c.231T&gt;C&#39;).
Only if &#39;use_gene&#39; is not enabled.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--use_protein

Use Protein level to generate HGVS annotation
(e.g. &#39;NP_689418:p.Cys77Arg&#39;).
Can be used with &#39;use_exon&#39; or &#39;use_gene&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--add_protein

Add Protein level to DNA HGVS annotation (e.g &#39;NM_152232:c.231T&gt;C,NP_689418:p.Cys77Arg&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--full_format

Generates HGVS annotation in a full format
by using all information to generates an exhaustive annotation
(non-standard, e.g. &#39;TAS1R2:NM_152232:NP_689418:c.231T&gt;C:p.Cys77Arg&#39;).
Use &#39;use_exon&#39; to add exon information
(e.g &#39;TAS1R2:NM_152232:NP_689418:exon2:c.231T&gt;C:p.Cys77Arg&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--codon_type=&lt;Codon type&gt; [&#39;1&#39;, &#39;3&#39;, &#39;FULL&#39;] (default: 3)

Amino Acide Codon format type to use to generate HGVS annotation.
Available:
- &#39;1&#39;: codon in 1 character (e.g. &#39;C&#39;, &#39;R&#39;)
- &#39;3&#39;: codon in 3 character (e.g. &#39;Cys&#39;, &#39;Arg&#39;)
-&#39;FULL&#39;: codon in full name (e.g. &#39;Cysteine&#39;, &#39;Arginine&#39;)</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--refgene=&lt;refGene&gt;

Path to refGene annotation file.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--refseqlink=&lt;refSeqLink&gt;

Path to refSeqLink annotation file.</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="6" id="annotation-tool"><span
class="header-section-number">6</span> ANNOTATION tool</h1>
<p>Annotation is mainly based on a build-in Parquet annotation method,
and tools such as BCFTOOLS, Annovar and snpEff. It uses available
databases (see Annovar and snpEff) and homemade databases. Format of
databases are: parquet, duckdb, vcf, bed, Annovar and snpEff (Annovar
and snpEff databases are automatically downloaded, see howard databases
tool).</p>
<p>Usage examples:</p>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.vcf.gz
&#x2013;annotations=&#x2018;tests/databases/annotations/current/hg19/avsnp150.parquet,tests/databases/annotations/current/hg19/dbnsfp42a.parquet,tests/databases/annotations/current/hg19/gnomad211_genome.parquet&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;assembly=hg19
&#x2013;annotations=&#x2018;annovar:refGene,annovar:cosmic70,snpeff,tests/databases/annotations/current/hg19/clinvar_20210123.parquet&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;assembly=hg19
&#x2013;annotation_parquet=&#x2018;tests/databases/annotations/current/hg19/avsnp150.parquet,tests/databases/annotations/current/hg19/dbnsfp42a.parquet&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;assembly=hg19
&#x2013;annotation_bcftools=&#x2018;tests/databases/annotations/current/hg19/nci60.vcf.gz,tests/databases/annotations/current/hg19/dbnsfp42a.vcf.gz&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;assembly=hg19
&#x2013;annotation_snpsift=&#x2018;tests/databases/annotations/current/hg19/nci60.vcf.gz,tests/databases/annotations/current/hg19/dbnsfp42a.vcf.gz&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;assembly=hg19
&#x2013;annotation_annovar=&#x2018;nci60:cosmic70&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;assembly=hg19
&#x2013;annotation_snpeff=&#x2018;-hgvs&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;assembly=hg19
&#x2013;annotation_exomiser=&#x2018;preset=exome:transcript_source=refseq&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;assembly=hg19
&#x2013;annotation_splice=&#x2018;split_mode=one:spliceai_distance=500:spliceai_mask=1&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;assembly=hg19
&#x2013;annotations=&#x2018;ALL:parquet&#x2019;</p>
</blockquote>
<blockquote>
<p>howard annotation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.tsv &#x2013;param=config/param.json</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="6.1" id="main-options-4"><span
class="header-section-number">6.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt; | required

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output=&lt;output&gt; | required

Output file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotations=&lt;annotations&gt;

Annotation with databases files, or with tools,
as a list of files in Parquet, VCF, BED, or keywords
 (e.g. &#39;file.parquet,bcftools:file2.vcf.gz,annovar:refGene,snpeff&#39;).
- For a Parquet/VCF/BED, use file paths
 (e.g. &#39;file1.parquet,file2.vcf.gz&#39;).
- For BCFTools annotation, use keyword &#39;bcftools&#39; with file paths
 (e.g. &#39;bcftools:file.vcf.gz:file.bed.gz&#39;).
- For Annovar annotation, use keyword &#39;annovar&#39; with annovar code
 (e.g. &#39;annovar:refGene&#39;, &#39;annovar:refGene:cosmic70&#39;).
- For snpeff annotation, use keyword &#39;snpeff&#39; with options
 (e.g. &#39;snpeff&#39;, &#39;snpeff:-hgvs -noShiftHgvs -spliceSiteSize 3&#39;).
- For snpSift annotation, use keyword &#39;snpsift&#39; with file paths
 (e.g. &#39;snpsift:file.vcf.gz:file.bed.gz&#39;).
- For Exomiser annotation, use keyword &#39;exomiser&#39; with options as key=value
 (e.g. &#39;exomiser:preset=exome:transcript_source=refseq&#39;).
- For add all availalbe databases files, use &#39;ALL&#39; keyword,
 with filters on type and release
 (e.g. &#39;ALL&#39;, &#39;ALL:parquet:current&#39;, &#39;ALL:parquet,vcf:current,devel&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotation_parquet=&lt;annotation parquet&gt;

Annotation with Parquet method, as a list of files in Parquet, VCF or BED
 (e.g. &#39;file1.parquet,file2.vcf.gz&#39;).
For add all availalbe databases files, use &#39;ALL&#39; keyword,
 with filters on type and release
 (e.g. &#39;ALL&#39;, &#39;ALL:parquet:current&#39;, &#39;ALL:parquet,vcf:current,devel&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotation_bcftools=&lt;annotation BCFTools&gt;

Annotation with BCFTools, as a list of files VCF or BED
 (e.g. &#39;file.vcf.gz,file.bed.gz&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotation_annovar=&lt;annotation Annovar&gt;

Annotation with Annovar, as a list of database keywords
 (e.g. &#39;refGene&#39;, &#39;refGene:cosmic70&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotation_snpeff=&lt;annotation snpEff&gt;

Annotation with snpEff, with options
 (e.g. &#39;&#39;, &#39;-hgvs -noShiftHgvs -spliceSiteSize 3&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotation_snpsift=&lt;annotation snpSift&gt;

Annotation with snpSift, as a list of files VCF
 (e.g. &#39;file.vcf.gz,file.bed.gz&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotation_exomiser=&lt;annotation Exomiser&gt;

Annotation with Exomiser, as a list of options
 (e.g. &#39;preset=exome:transcript_source=refseq&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotation_splice=&lt;annotation Splice&gt;

Annotation with Splice, as a list of options
 (e.g. &#39;split_mode=one:spliceai_distance=500:spliceai_mask=1&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--assembly=&lt;assembly&gt; (default: hg19)

Genome Assembly (e.g. &#39;hg19&#39;, &#39;hg38&#39;).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="6.2" id="annotation"><span
class="header-section-number">6.2</span> Annotation</h2>
<p><small></p>
<blockquote>
<pre><code>--annotations_update

Update option for annotation (Only for Parquet annotation).
If True, annotation fields will be removed and re-annotated.
These options will be applied to all annotation databases.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotations_append

Append option for annotation (Only for Parquet annotation).
If True, annotation fields will be annotated only if not annotation exists for the variant.
These options will be applied to all annotation databases.</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="7" id="calculation-tool"><span
class="header-section-number">7</span> CALCULATION tool</h1>
<p>Calculation processes variants information to generate new
information, such as: identify variation type (VarType), harmonizes
allele frequency (VAF) and calculate sttistics (VAF_stats), extracts
Nomen (transcript, cNomen, pNomen&#x2026;) from an HGVS field (e.g.&#xA0;snpEff,
Annovar) with an optional list of personalized transcripts, generates
VaRank format barcode, identify trio inheritance.</p>
<p>Usage examples:</p>
<blockquote>
<p>howard calculation &#x2013;input=tests/data/example.full.vcf
&#x2013;output=/tmp/example.calculation.tsv &#x2013;calculations=&#x2018;vartype&#x2019;</p>
</blockquote>
<blockquote>
<p>howard calculation &#x2013;input=tests/data/example.ann.vcf.gz
&#x2013;output=/tmp/example.calculated.tsv &#x2013;calculations=&#x2018;snpeff_hgvs,NOMEN&#x2019;
&#x2013;hgvs_field=snpeff_hgvs &#x2013;transcripts=tests/data/transcripts.tsv</p>
</blockquote>
<blockquote>
<p>howard calculation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.calculated.tsv &#x2013;calculations=&#x2018;TRIO&#x2019;
&#x2013;trio_pedigree=&#x2018;sample1,sample2,sample4&#x2019;</p>
</blockquote>
<blockquote>
<p>howard calculation &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.calculated.tsv &#x2013;calculations=&#x2018;BARCODEFAMILY&#x2019;
&#x2013;family_pedigree=&#x2018;sample1,sample2,sample4&#x2019;</p>
</blockquote>
<blockquote>
<p>howard calculation &#x2013;input=tests/data/example.ann.transcripts.vcf.gz
&#x2013;output=/tmp/example.calculation.transcripts.tsv
&#x2013;param=config/param.transcripts.json
&#x2013;calculations=&#x2018;TRANSCRIPTS_ANNOTATIONS,TRANSCRIPTS_PRIORITIZATION,TRANSCRIPTS_EXPORT&#x2019;</p>
</blockquote>
<blockquote>
<p>howard calculation &#x2013;input=tests/data/example.ann.vcf.gz
&#x2013;output=/tmp/example.ann.tsv &#x2013;param=config/param.json</p>
</blockquote>
<blockquote>
<p>howard calculation &#x2013;show_calculations</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="7.1" id="main-options-5"><span
class="header-section-number">7.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt;

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output=&lt;output&gt;

Output file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--calculations=&lt;operations&gt;

Quick calculations on genetic variants information and genotype information,
as a list of operations (e.g. &#39;VARTYPE,variant_id&#39;).
List of available calculations by default
 (unsensitive case, see doc for more information):
 VARTYPE  snpeff_hgvs  FINDBYPIPELINE  GENOTYPECONCORDANCE  BARCODE  TRIO  VAF  VAF_STATS  DP_STATS</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="7.2" id="calculation"><span
class="header-section-number">7.2</span> Calculation</h2>
<p><small></p>
<blockquote>
<pre><code>--calculation_config=&lt;calculation config&gt;

Calculation configuration JSON file.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--show_calculations

Show available calculation operations.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="7.3" id="nomen"><span
class="header-section-number">7.3</span> NOMEN</h2>
<p><small></p>
<blockquote>
<pre><code>--hgvs_field=&lt;HGVS field&gt; (default: hgvs)

HGVS INFO/tag containing a list o HGVS annotations.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--transcripts=&lt;transcripts&gt;

Transcripts TSV file,
with Transcript in first column, optional Gene in second column.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="7.4" id="trio"><span
class="header-section-number">7.4</span> TRIO</h2>
<p><small></p>
<blockquote>
<pre><code>--trio_pedigree=&lt;trio pedigree&gt;

Pedigree Trio for trio inheritance calculation.
Either a JSON file or JSON string or a list of samples
(e.g. &#39;sample1,sample2,sample3&#39; for father, mother and child,
 &#39;{&quot;father&quot;: &quot;sample1&quot;, &quot;mother&quot;: &quot;sample2&quot;, &quot;child&quot;: &quot;sample3&quot;}&#39;).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="7.5" id="barcodefamily"><span
class="header-section-number">7.5</span> BARCODEFAMILY</h2>
<p><small></p>
<blockquote>
<pre><code>--family_pedigree=&lt;family pedigree&gt;

Pedigree family for barcode calculation on genotype.
Either a JSON file or JSON string or a list of samples
(e.g. &#39;sample1,sample2,sample3,sample4&#39;,
 &#39;{&quot;father&quot;: &quot;sample1&quot;, &quot;mother&quot;: &quot;sample2&quot;, &quot;child1&quot;: &quot;sample3&quot;, &quot;child2&quot;: &quot;sample3&quot;}&#39;).</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="8" id="prioritization-tool"><span
class="header-section-number">8</span> PRIORITIZATION tool</h1>
<p>Prioritization algorithm uses profiles to flag variants (as passed or
filtered), calculate a prioritization score, and automatically generate
a comment for each variants (example: &#x2018;polymorphism identified in dbSNP.
associated to Lung Cancer. Found in ClinVar database&#x2019;). Prioritization
profiles are defined in a configuration file in JSON format. A profile
is defined as a list of annotation/value, using wildcards and comparison
options (contains, lower than, greater than, equal&#x2026;). Annotations fields
may be quality values (usually from callers, such as &#x2018;DP&#x2019;) or other
annotations fields provided by annotations tools, such as HOWARD itself
(example: COSMIC, Clinvar, 1000genomes, PolyPhen, SIFT). Multiple
profiles can be used simultaneously, which is useful to define multiple
validation/prioritization levels (example: &#x2018;standard&#x2019;, &#x2018;stringent&#x2019;,
&#x2018;rare variants&#x2019;, &#x2018;low allele frequency&#x2019;).</p>
<p>Usage examples:</p>
<blockquote>
<p>howard prioritization &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.prioritized.vcf.gz &#x2013;prioritizations=&#x2018;default&#x2019;</p>
</blockquote>
<blockquote>
<p>howard prioritization &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.prioritized.vcf.gz
&#x2013;prioritizations=&#x2018;default,GERMLINE&#x2019;
&#x2013;prioritization_config=config/prioritization_profiles.json</p>
</blockquote>
<blockquote>
<p>howard prioritization &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.prioritized.tsv &#x2013;param=config/param.json</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="8.1" id="main-options-6"><span
class="header-section-number">8.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt; | required

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output=&lt;output&gt; | required

Output file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--prioritizations=&lt;prioritisations&gt;

List of prioritization profiles to process (based on Prioritization JSON file),
such as &#39;default&#39;, &#39;rare variants&#39;, &#39;low allele frequency&#39;, &#39;GERMLINE&#39;.
By default, all profiles available will be processed.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="8.2" id="prioritization"><span
class="header-section-number">8.2</span> Prioritization</h2>
<p><small></p>
<blockquote>
<pre><code>--default_profile=&lt;default profile&gt;

Prioritization profile by default (see doc).
Default is the first profile in the list of prioritization profiles.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--pzfields=&lt;pzfields&gt; (default: PZScore,PZFlag)

Prioritization fields to provide (see doc).
Available: PZScore, PZFlag, PZTags, PZComment, PZInfos</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--prioritization_score_mode=&lt;prioritization score mode&gt; [&#39;HOWARD&#39;, &#39;VaRank&#39;] (default: HOWARD)

Prioritization Score mode (see doc).
Available: HOWARD (increment score), VaRank (max score)</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--prioritization_config=&lt;prioritization config&gt;

Prioritization configuration JSON file (defines profiles, see doc).</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="9" id="process-tool"><span
class="header-section-number">9</span> PROCESS tool</h1>
<p>howard process tool manage genetic variations to:</p>
<ul>
<li><p>annotates genetic variants with multiple annotation
databases/files and tools</p></li>
<li><p>calculates and normalizes annotations</p></li>
<li><p>prioritizes variants with profiles (list of citeria) to calculate
scores and flags</p></li>
<li><p>translates into various formats</p></li>
<li><p>query genetic variants and annotations</p></li>
<li><p>generates variants statistics</p></li>
</ul>
<p>Usage examples:</p>
<blockquote>
<p>howard process &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.annotated.vcf.gz &#x2013;param=config/param.json</p>
</blockquote>
<blockquote>
<p>howard process &#x2013;input=tests/data/example.vcf.gz &#x2013;annotations=&#x2018;snpeff&#x2019;
&#x2013;calculations=&#x2018;snpeff_hgvs&#x2019; &#x2013;prioritizations=&#x2018;default&#x2019; &#x2013;explode_infos
&#x2013;output=/tmp/example.annotated.tsv &#x2013;query=&#x2018;SELECT &#x201C;#CHROM&#x201D;, POS, ALT,
REF, snpeff_hgvs FROM variants&#x2019;</p>
</blockquote>
<blockquote>
<p>howard process &#x2013;input=tests/data/example.vcf.gz
&#x2013;hgvs_options=&#x2018;full_format,use_exon&#x2019; &#x2013;explode_infos
&#x2013;output=/tmp/example.annotated.tsv &#x2013;query=&#x2018;SELECT &#x201C;#CHROM&#x201D;, POS, ALT,
REF, hgvs FROM variants&#x2019;</p>
</blockquote>
<blockquote>
<p>howard process &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.howard.vcf.gz &#x2013;hgvs=&#x2018;full_format,use_exon&#x2019;
&#x2013;annotations=&#x2018;tests/databases/annotations/current/hg19/avsnp150.parquet,tests/databases/annotations/current/hg19/dbnsfp42a.parquet,tests/databases/annotations/current/hg19/gnomad211_genome.parquet&#x2019;
&#x2013;calculations=&#x2018;NOMEN&#x2019; &#x2013;explode_infos &#x2013;query=&#x2018;SELECT NOMEN, REVEL_score,
SIFT_score, AF AS &#x2019;gnomad_AF&#x2019;, ClinPred_score, ClinPred_pred FROM
variants&#x2019;</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="9.1" id="main-options-7"><span
class="header-section-number">9.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt; | required

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output=&lt;output&gt; | required

Output file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--hgvs_options=&lt;HGVS options&gt;

Quick HGVS annotation options.
This option will skip all other hgvs options.
Examples:
- &#39;default&#39; (for default options)
- &#39;full_format&#39; (for full format HGVS annotation)
- &#39;use_gene=True:add_protein=true:codon_type=FULL&#39;</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotations=&lt;annotations&gt;

Annotation with databases files, or with tools,
as a list of files in Parquet, VCF, BED, or keywords
 (e.g. &#39;file.parquet,bcftools:file2.vcf.gz,annovar:refGene,snpeff&#39;).
- For a Parquet/VCF/BED, use file paths
 (e.g. &#39;file1.parquet,file2.vcf.gz&#39;).
- For BCFTools annotation, use keyword &#39;bcftools&#39; with file paths
 (e.g. &#39;bcftools:file.vcf.gz:file.bed.gz&#39;).
- For Annovar annotation, use keyword &#39;annovar&#39; with annovar code
 (e.g. &#39;annovar:refGene&#39;, &#39;annovar:refGene:cosmic70&#39;).
- For snpeff annotation, use keyword &#39;snpeff&#39; with options
 (e.g. &#39;snpeff&#39;, &#39;snpeff:-hgvs -noShiftHgvs -spliceSiteSize 3&#39;).
- For snpSift annotation, use keyword &#39;snpsift&#39; with file paths
 (e.g. &#39;snpsift:file.vcf.gz:file.bed.gz&#39;).
- For Exomiser annotation, use keyword &#39;exomiser&#39; with options as key=value
 (e.g. &#39;exomiser:preset=exome:transcript_source=refseq&#39;).
- For add all availalbe databases files, use &#39;ALL&#39; keyword,
 with filters on type and release
 (e.g. &#39;ALL&#39;, &#39;ALL:parquet:current&#39;, &#39;ALL:parquet,vcf:current,devel&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--calculations=&lt;operations&gt;

Quick calculations on genetic variants information and genotype information,
as a list of operations (e.g. &#39;VARTYPE,variant_id&#39;).
List of available calculations by default
 (unsensitive case, see doc for more information):
 VARTYPE  snpeff_hgvs  FINDBYPIPELINE  GENOTYPECONCORDANCE  BARCODE  TRIO  VAF  VAF_STATS  DP_STATS</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--prioritizations=&lt;prioritisations&gt;

List of prioritization profiles to process (based on Prioritization JSON file),
such as &#39;default&#39;, &#39;rare variants&#39;, &#39;low allele frequency&#39;, &#39;GERMLINE&#39;.
By default, all profiles available will be processed.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--assembly=&lt;assembly&gt; (default: hg19)

Genome Assembly (e.g. &#39;hg19&#39;, &#39;hg38&#39;).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="9.2" id="hgvs-1"><span
class="header-section-number">9.2</span> HGVS</h2>
<p><small></p>
<blockquote>
<pre><code>--use_gene

Use Gene information to generate HGVS annotation
(e.g. &#39;NM_152232(TAS1R2):c.231T&gt;C&#39;)</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--use_exon

Use Exon information to generate HGVS annotation
(e.g. &#39;NM_152232(exon2):c.231T&gt;C&#39;).
Only if &#39;use_gene&#39; is not enabled.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--use_protein

Use Protein level to generate HGVS annotation
(e.g. &#39;NP_689418:p.Cys77Arg&#39;).
Can be used with &#39;use_exon&#39; or &#39;use_gene&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--add_protein

Add Protein level to DNA HGVS annotation (e.g &#39;NM_152232:c.231T&gt;C,NP_689418:p.Cys77Arg&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--full_format

Generates HGVS annotation in a full format
by using all information to generates an exhaustive annotation
(non-standard, e.g. &#39;TAS1R2:NM_152232:NP_689418:c.231T&gt;C:p.Cys77Arg&#39;).
Use &#39;use_exon&#39; to add exon information
(e.g &#39;TAS1R2:NM_152232:NP_689418:exon2:c.231T&gt;C:p.Cys77Arg&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--codon_type=&lt;Codon type&gt; [&#39;1&#39;, &#39;3&#39;, &#39;FULL&#39;] (default: 3)

Amino Acide Codon format type to use to generate HGVS annotation.
Available:
- &#39;1&#39;: codon in 1 character (e.g. &#39;C&#39;, &#39;R&#39;)
- &#39;3&#39;: codon in 3 character (e.g. &#39;Cys&#39;, &#39;Arg&#39;)
-&#39;FULL&#39;: codon in full name (e.g. &#39;Cysteine&#39;, &#39;Arginine&#39;)</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--refgene=&lt;refGene&gt;

Path to refGene annotation file.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--refseqlink=&lt;refSeqLink&gt;

Path to refSeqLink annotation file.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="9.3" id="annotation-1"><span
class="header-section-number">9.3</span> Annotation</h2>
<p><small></p>
<blockquote>
<pre><code>--annotations_update

Update option for annotation (Only for Parquet annotation).
If True, annotation fields will be removed and re-annotated.
These options will be applied to all annotation databases.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annotations_append

Append option for annotation (Only for Parquet annotation).
If True, annotation fields will be annotated only if not annotation exists for the variant.
These options will be applied to all annotation databases.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="9.4" id="calculation-1"><span
class="header-section-number">9.4</span> Calculation</h2>
<p><small></p>
<blockquote>
<pre><code>--calculation_config=&lt;calculation config&gt;

Calculation configuration JSON file.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="9.5" id="prioritization-1"><span
class="header-section-number">9.5</span> Prioritization</h2>
<p><small></p>
<blockquote>
<pre><code>--default_profile=&lt;default profile&gt;

Prioritization profile by default (see doc).
Default is the first profile in the list of prioritization profiles.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--pzfields=&lt;pzfields&gt; (default: PZScore,PZFlag)

Prioritization fields to provide (see doc).
Available: PZScore, PZFlag, PZTags, PZComment, PZInfos</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--prioritization_score_mode=&lt;prioritization score mode&gt; [&#39;HOWARD&#39;, &#39;VaRank&#39;] (default: HOWARD)

Prioritization Score mode (see doc).
Available: HOWARD (increment score), VaRank (max score)</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--prioritization_config=&lt;prioritization config&gt;

Prioritization configuration JSON file (defines profiles, see doc).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="9.6" id="query-1"><span
class="header-section-number">9.6</span> Query</h2>
<p><small></p>
<blockquote>
<pre><code>--query=&lt;query&gt;

Query in SQL format
(e.g. &#39;SELECT * FROM variants LIMIT 50&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--query_limit=&lt;query limit&gt; (default: 10)

Limit of number of row for query (only for print result, not output).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--query_print_mode=&lt;print mode&gt; [None, &#39;markdown&#39;, &#39;tabulate&#39;, &#39;disabled&#39;]

Print mode of query result (only for print result, not output).
Either None (native), &#39;markdown&#39;, &#39;tabulate&#39; or disabled.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="9.7" id="explode-2"><span
class="header-section-number">9.7</span> Explode</h2>
<p><small></p>
<blockquote>
<pre><code>--explode_infos

Explode VCF INFO/Tag into &#39;variants&#39; table columns.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_prefix=&lt;explode infos prefix&gt;

Explode VCF INFO/Tag with a specific prefix.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_fields=&lt;explode infos list&gt; (default: *)

Explode VCF INFO/Tag specific fields/tags.
Keyword `*` specify all available fields, except those already specified.
Pattern (regex) can be used, such as `.*_score` for fields named with &#39;_score&#39; at the end.
Examples:
- &#39;HGVS,SIFT,Clinvar&#39; (list of fields)
- &#39;HGVS,*,Clinvar&#39; (list of fields with all other fields at the end)
- &#39;HGVS,.*_score,Clinvar&#39; (list of 2 fields with all scores in the middle)
- &#39;HGVS,.*_score,*&#39; (1 field, scores, all other fields)
- &#39;HGVS,*,.*_score&#39; (1 field, all other fields, all scores)</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="9.8" id="export-2"><span
class="header-section-number">9.8</span> Export</h2>
<p><small></p>
<blockquote>
<pre><code>--include_header

Include header (in VCF format) in output file.
Only for compatible formats (tab-delimiter format as TSV or BED).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--order_by=&lt;order by&gt;

List of columns to sort the result-set in ascending or descending order.
Use SQL format, and keywords ASC (ascending) and DESC (descending).
If a column is not available, order will not be considered.
Order is enable only for compatible format (e.g. TSV, CSV, JSON).
Examples: &#39;ACMG_score DESC&#39;, &#39;PZFlag DESC, PZScore DESC&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--parquet_partitions=&lt;parquet partitions&gt;

Parquet partitioning using hive (available for any format).
This option is faster parallel writing, but memory consuming.
Use &#39;None&#39; (string) for NO partition but split parquet files into a folder.
Examples: &#39;#CHROM&#39;, &#39;#CHROM,REF&#39;, &#39;None&#39;.</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="10" id="databases-tool"><span
class="header-section-number">10</span> DATABASES tool</h1>
<p>Download databases and needed files for howard and associated
tools</p>
<p>Usage examples:</p>
<blockquote>
<p>howard databases &#x2013;assembly=hg19
&#x2013;download-genomes=~/howard/databases/genomes/current
&#x2013;download-genomes-provider=UCSC
&#x2013;download-genomes-contig-regex=&#x2018;chr[0-9XYM]+$&#x2019;</p>
</blockquote>
<blockquote>
<p>howard databases &#x2013;assembly=hg19
&#x2013;download-annovar=~/howard/databases/annovar/current
&#x2013;download-annovar-files=&#x2018;refGene,cosmic70,nci60&#x2019;</p>
</blockquote>
<blockquote>
<p>howard databases &#x2013;assembly=hg19
&#x2013;download-snpeff=~/howard/databases/snpeff/current</p>
</blockquote>
<blockquote>
<p>howard databases &#x2013;assembly=hg19
&#x2013;download-refseq=~/howard/databases/refseq/current
&#x2013;download-refseq-format-file=&#x2018;ncbiRefSeq.txt&#x2019;</p>
</blockquote>
<blockquote>
<p>howard databases &#x2013;assembly=hg19
&#x2013;download-dbnsfp=~/howard/databases/dbnsfp/current
&#x2013;download-dbnsfp-release=&#x2018;4.4a&#x2019; &#x2013;download-dbnsfp-subdatabases</p>
</blockquote>
<blockquote>
<p>howard databases &#x2013;assembly=hg19
&#x2013;download-alphamissense=~/howard/databases/alphamissense/current</p>
</blockquote>
<blockquote>
<p>howard databases &#x2013;assembly=hg19
&#x2013;download-exomiser=~/howard/databases/exomiser/current</p>
</blockquote>
<blockquote>
<p>howard databases &#x2013;assembly=hg19
&#x2013;download-dbsnp=~/howard/databases/dbsnp/current &#x2013;download-dbsnp-vcf</p>
</blockquote>
<blockquote>
<p>cd ~/howard/databases &amp;&amp; howard databases &#x2013;assembly=hg19
&#x2013;download-genomes=genomes/current &#x2013;download-genomes-provider=UCSC
&#x2013;download-genomes-contig-regex=&#x2018;chr[0-9XYM]+$&#x2019;
&#x2013;download-annovar=annovar/current
&#x2013;download-annovar-files=&#x2018;refGene,cosmic70,nci60&#x2019;
&#x2013;download-snpeff=snpeff/current &#x2013;download-refseq=refseq/current
&#x2013;download-refseq-format-file=&#x2018;ncbiRefSeq.txt&#x2019;
&#x2013;download-dbnsfp=dbnsfp/current &#x2013;download-dbnsfp-release=&#x2018;4.4a&#x2019;
&#x2013;download-dbnsfp-subdatabases
&#x2013;download-alphamissense=alphamissense/current
&#x2013;download-exomiser=exomiser/current &#x2013;download-dbsnp=dbsnp/current
&#x2013;download-dbsnp-vcf &#x2013;threads=8</p>
</blockquote>
<blockquote>
<p>howard databases &#x2013;generate-param=/tmp/param.json
&#x2013;generate-param-description=/tmp/test.description.json
&#x2013;generate-param-formats=parquet</p>
</blockquote>
<blockquote>
<p>howard databases &#x2013;input_annovar=tests/databases/others/hg19_nci60.txt
&#x2013;output_annovar=/tmp/nci60.from_annovar.vcf.gz
&#x2013;annovar_to_parquet=/tmp/nci60.from_annovar.parquet &#x2013;annovar_code=nci60
&#x2013;genome=~/howard/databases/genomes/current/hg19.fa</p>
</blockquote>
<p>Notes:</p>
<blockquote>
<ul>
<li>Downloading databases can take a while, depending on network,
threads and memory</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>Proxy: Beware of network and proxy configuration</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>dbNSFP download: More threads, more memory usage (8 threads ~ 16Gb,
24 threads ~ 32Gb)</li>
</ul>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="10.1" id="main-options-8"><span
class="header-section-number">10.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--assembly=&lt;assembly&gt; (default: hg19)

Genome Assembly (e.g. &#39;hg19&#39;, &#39;hg38&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--genomes-folder=&lt;genomes&gt; (default: ~/howard/databases/genomes/current)

Folder containing genomes.
(e.g. &#39;~/howard/databases/genomes/current&#39;</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--genome=&lt;genome&gt; (default: ~/howard/databases/genomes/current/hg19/hg19.fa)

Genome file in fasta format (e.g. &#39;hg19.fa&#39;, &#39;hg38.fa&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.2" id="genomes"><span
class="header-section-number">10.2</span> Genomes</h2>
<p><small></p>
<blockquote>
<pre><code>--download-genomes=&lt;genomes&gt;

Path to genomes folder
with Fasta files, indexes,
and all files generated by pygenome module.
(e.g. &#39;~/howard/databases/genomes/current&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-genomes-provider=&lt;genomes provider&gt; [&#39;GENCODE&#39;, &#39;Ensembl&#39;, &#39;UCSC&#39;, &#39;NCBI&#39;] (default: UCSC)

Download Genome from an external provider.
Available: GENCODE, Ensembl, UCSC, NCBI.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-genomes-contig-regex=&lt;genomes contig regex&gt;

Regular expression to select specific chromosome
(e.g &#39;chr[0-9XYM]+$&#39;).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.3" id="snpeff"><span
class="header-section-number">10.3</span> snpEff</h2>
<p><small></p>
<blockquote>
<pre><code>--download-snpeff=&lt;snpEff&gt;

Download snpEff databases within snpEff folder</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.4" id="annovar"><span
class="header-section-number">10.4</span> Annovar</h2>
<p><small></p>
<blockquote>
<pre><code>--download-annovar=&lt;Annovar&gt;

Path to Annovar databases
(e.g. &#39;~/howard/databases/annovar/current&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-annovar-files=&lt;Annovar code&gt;

Download Annovar databases for a list of Annovar file code (see Annovar Doc).
Use None to donwload all available files,
or Annovar keyword (e.g. &#39;refGene&#39;, &#39;cosmic70&#39;, &#39;clinvar_202*&#39;).
Note that refGene will at least be downloaded,
and only files that not already exist or changed will be downloaded.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-annovar-url=&lt;Annovar url&gt; (default: http://www.openbioinformatics.org/annovar/download)

Annovar databases URL (see Annovar Doc).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.5" id="refseq"><span
class="header-section-number">10.5</span> refSeq</h2>
<p><small></p>
<blockquote>
<pre><code>--download-refseq=&lt;refSeq&gt;

Path to refSeq databases
(e.g. &#39;~/howard/databases/refseq/current&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-url=&lt;refSeq url&gt; (default: http://hgdownload.soe.ucsc.edu/goldenPath)

refSeq databases URL (see refSeq WebSite)
(e.g. &#39;http://hgdownload.soe.ucsc.edu/goldenPath&#39;)&#x2022;/n</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-prefix=&lt;refSeq prefix&gt; (default: ncbiRefSeq)

Check existing refSeq files in refSeq folder.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-files=&lt;refSeq files&gt; (default: ncbiRefSeq.txt,ncbiRefSeqLink.txt)

List of refSeq files to download.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-format-file=&lt;refSeq format file&gt;

Name of refSeq file to convert in BED format
(e.g. &#39;ncbiRefSeq.txt&#39;).
Process only if not None.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-include-utr5

Formating BED refSeq file including 5&#39;UTR.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-include-utr3

Formating BED refSeq file including 3&#39;UTR.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-include-chrM

Formating BED refSeq file including Mitochondiral chromosome &#39;chrM&#39; or &#39;chrMT&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-include-non-canonical-chr

Formating BED refSeq file including non canonical chromosomes.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-include-non-coding-transcripts

Formating BED refSeq file including non coding transcripts.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-refseq-include-transcript-version

Formating BED refSeq file including transcript version.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.6" id="dbnsfp"><span
class="header-section-number">10.6</span> dbNSFP</h2>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp=&lt;dbNSFP&gt;

Download dbNSFP databases within dbNSFP folder(e.g. &#39;~/howard/databases&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-url=&lt;dbNSFP url&gt; (default: https://dbnsfp.s3.amazonaws.com)

Download dbNSFP databases URL (see dbNSFP website)
(e.g. https://dbnsfp.s3.amazonaws.com&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-release=&lt;dnNSFP release&gt; (default: 4.4a)

Release of dbNSFP to download (see dbNSFP website)
(e.g. &#39;4.4a&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-parquet-size=&lt;dbNSFP parquet size&gt; (default: 100)

Maximum size (Mb) of data files in Parquet folder.
Parquet folder are partitioned (hive) by chromosome (sub-folder),
which contain N data files.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-subdatabases

Generate dbNSFP sub-databases.
dbNSFP provides multiple databases which are split onto multiple columns.
This option create a Parquet folder for each sub-database (based on columns names).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-parquet

Generate a Parquet file for each Parquet folder.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-vcf

Generate a VCF file for each Parquet folder.
Need genome FASTA file (see --download-genome).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-no-files-all

Not generate database Parquet/VCF file for the entire database (&#39;ALL&#39;).
Only sub-databases files will be generated.
(see &#39;--download-dbnsfp-subdatabases&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-add-info

Add INFO column (VCF format) in Parquet folder and file.
Useful for speed up full annotation (all available columns).
Increase memory and space during generation of files.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-only-info

Add only INFO column (VCF format) in Parquet folder and file.
Useful for speed up full annotation (all available columns).
Decrease memory and space during generation of files.
Increase time for partial annotation (some available columns).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-uniquify

Uniquify values within column
(e.g. &quot;D,D&quot; to &quot;D&quot;, &quot;D,.,T&quot; to &quot;D,T&quot;).
Remove transcripts information details.
Usefull to reduce size of the database.
Increase memory and space during generation of files.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbnsfp-row-group-size=&lt;dnNSFP row grooup size&gt; (default: 100000)

Minimum number of rows in a parquet row group (see duckDB doc).
Lower can reduce memory usage and slightly increase space during generation,
speed up highly selective queries, slow down whole file queries (e.g. aggregations).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.7" id="alphamissense"><span
class="header-section-number">10.7</span> AlphaMissense</h2>
<p><small></p>
<blockquote>
<pre><code>--download-alphamissense=&lt;AlphaMissense&gt;

Path to AlphaMissense databases</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-alphamissense-url=&lt;AlphaMissense url&gt; (default: https://storage.googleapis.com/dm_alphamissense)

Download AlphaMissense databases URL (see AlphaMissense website)
(e.g. &#39;https://storage.googleapis.com/dm_alphamissense&#39;).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.8" id="exomiser"><span
class="header-section-number">10.8</span> Exomiser</h2>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser=&lt;Exomiser&gt;

Path to Exomiser databases
(e.g. ~/howard/databases/exomiser/current).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-application-properties=&lt;Exomiser application properties&gt;

Exomiser Application Properties configuration file (see Exomiser website).
This file contains configuration settings for the Exomiser tool.
If this parameter is not provided, the function will attempt to locate
the application properties file automatically based on the Exomiser.
Configuration information will be used to download expected releases (if no other parameters).
CADD and REMM will be downloaded only if &#39;path&#39; are provided.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-url=&lt;Exomiser url&gt; (default: http://data.monarchinitiative.org/exomiser)

URL where Exomiser database files can be downloaded from
(e.g. &#39;http://data.monarchinitiative.org/exomiser&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-release=&lt;Exomiser release&gt;

Release of Exomiser data to download.
If &quot;default&quot;, &quot;auto&quot;, or &quot;config&quot;, retrieve from Application Properties file.
If not provided (None), from Application Properties file (Exomiser data-version) 
or default &#39;2109&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-phenotype-release=&lt;Exomiser phenoptye release&gt;

Release of Exomiser phenotype to download.
If not provided (None), from Application Properties file (Exomiser Phenotype data-version)
or Exomiser release.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-remm-release=&lt;Exomiser remm release&gt;

Release of ReMM (Regulatory Mendelian Mutation) database to download.
If &quot;default&quot;, &quot;auto&quot;, or &quot;config&quot;, retrieve from Application Properties file.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-remm-url=&lt;Exomiser remm url&gt; (default: https://kircherlab.bihealth.org/download/ReMM)

URL where ReMM (Regulatory Mendelian Mutation) database files can be downloaded from
(e.g. &#39;https://kircherlab.bihealth.org/download/ReMM&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-cadd-release=&lt;Exomiser cadd release&gt;

Release of CADD (Combined Annotation Dependent Depletion) database to download.
If &quot;default&quot;, &quot;auto&quot;, or &quot;config&quot;, retrieve from Application Properties file.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-cadd-url=&lt;Exomiser cadd url&gt; (default: https://kircherlab.bihealth.org/download/CADD)

URL where CADD (Combined Annotation Dependent Depletion) database files can be downloaded from
(e.g. &#39;https://kircherlab.bihealth.org/download/CADD&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-cadd-url-snv-file=&lt;Exomiser url snv file&gt; (default: whole_genome_SNVs.tsv.gz)

Name of the file containing the SNV (Single Nucleotide Variant) data
for the CADD (Combined Annotation Dependent Depletion) database.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-exomiser-cadd-url-indel-file=&lt;Exomiser cadd url indel&gt; (default: InDels.tsv.gz)

Name of the file containing the INDEL (Insertion-Deletion) data
for the CADD (Combined Annotation Dependent Depletion) database.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.9" id="dbsnp"><span
class="header-section-number">10.9</span> dbSNP</h2>
<p><small></p>
<blockquote>
<pre><code>--download-dbsnp=&lt;dnSNP&gt;

Path to dbSNP databases
(e.g. &#39;~/howard/databases/exomiser/dbsnp&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbsnp-releases=&lt;dnSNP releases&gt; (default: b156)

Release of dbSNP to download
(e.g. &#39;b152&#39;, &#39;b152,b156&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbsnp-release-default=&lt;dnSNP release default&gt;

Default Release of dbSNP (&#39;default&#39; symlink)
(e.g. &#39;b156&#39;).
If None, first release to download will be assigned as default
only if it does not exists.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbsnp-url=&lt;dbSNP url&gt; (default: https://ftp.ncbi.nih.gov/snp/archive)

URL where dbSNP database files can be downloaded from.
(e.g. &#39;https://ftp.ncbi.nih.gov/snp/archive&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbsnp-url-files=&lt;dbSNP url files&gt;

Dictionary that maps assembly names to specific dbSNP URL files.
It allows you to provide custom dbSNP URL files for specific assemblies
instead of using the default file naming convention.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbsnp-url-files-prefix=&lt;dbSNP url files prefix&gt; (default: GCF_000001405)

String that represents the prefix of the dbSNP file name for a specific assembly.
It is used to construct the full URL of the dbSNP file to be downloaded.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbsnp-assemblies-map=&lt;dbSNP assemblies map&gt; (default: {&#39;hg19&#39;: &#39;25&#39;, &#39;hg38&#39;: &#39;40&#39;})

dictionary that maps assembly names to their corresponding dbSNP versions.
It is used to construct the dbSNP file name based on the assembly name.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbsnp-vcf

Generate well-formatted VCF from downloaded file:
- Add and filter contigs associated to assembly
- Normalize by splitting multiallelics
- Need genome (see --download-genome)</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--download-dbsnp-parquet

Generate Parquet file from VCF.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.10" id="hgmd"><span
class="header-section-number">10.10</span> HGMD</h2>
<p><small></p>
<blockquote>
<pre><code>--convert-hgmd=&lt;HGMD&gt;

Convert HGMD databases.
Folder where the HGMD databases will be stored.
Fields in VCF, Parquet and TSV will be generated.
If the folder does not exist, it will be created.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--convert-hgmd-file=&lt;HGMD file&gt;

File from HGMD.
Name format &#39;HGMD_Pro_&lt;release&gt;_&lt;assembly&gt;.vcf.gz&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--convert-hgmd-basename=&lt;HGMD basename&gt;

File output basename.
Generated files will be prefixed by basename
(e.g. &#39;HGMD_Pro_MY_RELEASE&#39;)
By default (None), input file name without &#39;.vcf.gz&#39;.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.11" id="from_annovar"><span
class="header-section-number">10.11</span> from_Annovar</h2>
<p><small></p>
<blockquote>
<pre><code>--input_annovar=&lt;input annovar&gt;

Input Annovar file path.
Format file must be a Annovar TXT file, associated with &#39;.idx&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output_annovar=&lt;output annovar&gt;

Output Annovar file path.
Format file must be either VCF compressesd file &#39;.vcf.gz&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annovar_code=&lt;Annovar code&gt;

Annovar code, or database name.
Usefull to name databases columns.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annovar_to_parquet=&lt;to parquet&gt;

Parquet file conversion.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annovar_reduce_memory=&lt;reduce memory&gt; [&#39;auto&#39;, &#39;enable&#39;, &#39;disable&#39;] (default: auto)

Reduce memory option for Annovar convert,
either &#39;auto&#39; (auto-detection), &#39;enable&#39; or &#39;disable&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--annovar_multi_variant=&lt;Annovar multi variant&gt; [&#39;auto&#39;, &#39;enable&#39;, &#39;disable&#39;] (default: auto)

Variant with multiple annotation lines on Annovar file.
Either &#39;auto&#39; (auto-detection), &#39;enable&#39; or &#39;disable&#39;.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.12" id="from_extann"><span
class="header-section-number">10.12</span> from_extann</h2>
<p><small></p>
<blockquote>
<pre><code>--input_extann=&lt;input extann&gt;

Input Extann file path.
Format file must be a Extann TXT file or TSV file.
File need to have at least the genes column.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output_extann=&lt;output extann&gt;

Output Extann file path.
Output extann file, should be BED or BED.gz.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--refgene=&lt;refGene&gt;

Path to refGene annotation file.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--transcripts=&lt;transcripts&gt;

Transcripts TSV file,
with Transcript in first column, optional Gene in second column.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param_extann=&lt;param extann&gt;

Param extann file path.
Param containing configuration, options to replace chars and
bedlike header description, conf vcf specs.
(e.g. &#39;~/howard/config/param.extann.json&#39;)</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--mode_extann=&lt;mode extann&gt; [&#39;all&#39;, &#39;longest&#39;, &#39;chosen&#39;] (default: longest)

Mode extann selection.
How to pick transcript from ncbi, keep all,
keep the longest, or keep the chosen one (transcript_extann).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="10.13" id="parameters"><span
class="header-section-number">10.13</span> Parameters</h2>
<p><small></p>
<blockquote>
<pre><code>--generate-param=&lt;param&gt;

Parameter file (JSON) with all databases found.
Databases folders scanned are defined in config file.
Structure of databases follow this structure (see doc):
.../&lt;database&gt;/&lt;release&gt;/&lt;assembly&gt;/*.[parquet|vcf.gz|...]</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--generate-param-description=&lt;param description&gt;

Description file (JSON) with all databases found.
Contains all databases with description of format, assembly, fields...</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--generate-param-releases=&lt;param release&gt; (default: current)

List of database folder releases to check
(e.g. &#39;current&#39;, &#39;latest&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--generate-param-formats=&lt;param formats&gt; (default: parquet)

List of database formats to check
(e.g. &#39;parquet&#39;, &#39;parquet,vcf,bed,tsv&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--generate-param-bcftools

Generate parameter JSON file with BCFTools annotation for allowed formats
(i.e. &#39;vcf&#39;, &#39;bed&#39;).</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="11" id="gui-tool"><span
class="header-section-number">11</span> GUI tool</h1>
<p>Graphical User Interface tools</p>
<p>Usage examples:</p>
<blockquote>
<p>howard gui</p>
</blockquote>
<h1 data-number="12" id="help-tool"><span
class="header-section-number">12</span> HELP tool</h1>
<p>Help tools</p>
<p>Usage examples:</p>
<blockquote>
<p>howard help &#x2013;help_md=docs/help.md &#x2013;help_html=docs/html/help.html
&#x2013;help_pdf=docs/pdf/help.pdf</p>
</blockquote>
<blockquote>
<p>howard help &#x2013;help_json_input=docs/json/help.configuration.json
&#x2013;help_json_input_title=&#x2018;HOWARD Configuration&#x2019;
&#x2013;help_md=docs/help.configuration.md
&#x2013;help_html=docs/html/help.configuration.html
&#x2013;help_pdf=docs/pdf/help.configuration.pdf &#x2013;code_type=&#x2018;json&#x2019;</p>
</blockquote>
<blockquote>
<p>howard help &#x2013;help_json_input=docs/json/help.parameteres.json
&#x2013;help_json_input_title=&#x2018;HOWARD Parameters&#x2019;
&#x2013;help_md=docs/help.parameteres.md
&#x2013;help_html=docs/html/help.parameteres.html
&#x2013;help_pdf=docs/pdf/help.parameteres.pdf &#x2013;code_type=&#x2018;json&#x2019;</p>
</blockquote>
<blockquote>
<p>howard help
&#x2013;help_json_input=docs/json/help.parameteres.databases.json
&#x2013;help_json_input_title=&#x2018;HOWARD Parameters Databases&#x2019;
&#x2013;help_md=docs/help.parameteres.databases.md
&#x2013;help_html=docs/html/help.parameteres.databases.html
&#x2013;help_pdf=docs/pdf/help.parameteres.databases.pdf &#x2013;code_type=&#x2018;json&#x2019;</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="12.1" id="main-options-9"><span
class="header-section-number">12.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--help_md=&lt;help markdown&gt;

Help Output file in MarkDown format.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--help_html=&lt;help html&gt;

Help Output file in HTML format.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--help_pdf=&lt;help pdf&gt;

Help Output file in PDF format.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--help_md_input=&lt;help MarkDown input&gt;

Help input file in MarkDown format.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--help_json_input=&lt;help JSON input&gt;

Help input file in JSON format.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--help_json_input_title=&lt;help JSON input title&gt; (default: Help)

Help JSON input title.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--code_type=&lt;example code type&gt;

Help example code type for input JSON format
(e.g. &#39;json&#39;, &#39;bash&#39;).</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="13" id="update_database-tool"><span
class="header-section-number">13</span> UPDATE_DATABASE tool</h1>
<p>Update HOWARD database</p>
<p>Usage examples:</p>
<blockquote>
<p>howard update_database &#x2013;database clinvar &#x2013;databases_folder
/home1/DB/HOWARD &#x2013;update_config update_databases.json</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="13.1" id="main-options-10"><span
class="header-section-number">13.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="13.2" id="update_database"><span
class="header-section-number">13.2</span> Update_database</h2>
<p><small></p>
<blockquote>
<pre><code>--databases_folder=&lt;databases_folder&gt; (default: ~/howard/databases)

Path of HOWARD database folder.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--database=&lt;database&gt; [&#39;clinvar&#39;] (default: clinvar)

Which database to update.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--update_config=&lt;update_config&gt;

Path of json configuration file.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--current_folder=&lt;current_folder&gt; (default: current)

Path of json configuration file.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="13.3" id="options"><span
class="header-section-number">13.3</span> Options</h2>
<p><small></p>
<blockquote>
<pre><code>--show=&lt;show&gt;

None</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--limit=&lt;limit&gt;

None</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="14" id="transcripts_check-tool"><span
class="header-section-number">14</span> TRANSCRIPTS_CHECK tool</h1>
<p>Check if a transcript list is present in a generated transcript table
from a input VCF file.</p>
<p>Usage examples:</p>
<blockquote>
<p>howard transcripts_check
&#x2013;input=plugins/transcripts_check/tests/data/example.ann.transcripts.vcf.gz
&#x2013;param=plugins/transcripts_check/tests/data/param.transcripts.json
&#x2013;transcripts_expected=plugins/transcripts_check/tests/data/transcripts.tsv
&#x2013;stats=/tmp/transcripts.stats.json
&#x2013;transcripts_missing=/tmp/transcripts.missing.tsv</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="14.1" id="main-options-11"><span
class="header-section-number">14.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt; | required

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {}) | required

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--transcripts_expected=&lt;List of transcripts (file)&gt; | required

File with a list of transcripts in first column.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--transcripts_missing=&lt;List of missing transcripts (file)&gt;

File with a list of missing transcripts in first column.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--stats_json=&lt;stats json&gt;

Stats Output file in JSON format.</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="15" id="genebe-tool"><span
class="header-section-number">15</span> GENEBE tool</h1>
<p>GeneBe annotation using REST API (see https://genebe.net/).</p>
<p>Usage examples:</p>
<blockquote>
<p>howard genebe &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.genebe.vcf.gz &#x2013;genebe_use_refseq</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="15.1" id="main-options-12"><span
class="header-section-number">15.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt; | required

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output=&lt;output&gt; | required

Output file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--assembly=&lt;assembly&gt; (default: hg19)

Genome Assembly (e.g. &#39;hg19&#39;, &#39;hg38&#39;).</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="15.2" id="genebe"><span
class="header-section-number">15.2</span> GeneBe</h2>
<p><small></p>
<blockquote>
<pre><code>--genebe_use_refseq

Use refSeq to annotate (default).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--genebe_use_ensembl

Use Ensembl to annotate.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--not_flatten_consequences

Use exploded annotation informations.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="15.3" id="explode-3"><span
class="header-section-number">15.3</span> Explode</h2>
<p><small></p>
<blockquote>
<pre><code>--explode_infos

Explode VCF INFO/Tag into &#39;variants&#39; table columns.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_prefix=&lt;explode infos prefix&gt;

Explode VCF INFO/Tag with a specific prefix.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_fields=&lt;explode infos list&gt; (default: *)

Explode VCF INFO/Tag specific fields/tags.
Keyword `*` specify all available fields, except those already specified.
Pattern (regex) can be used, such as `.*_score` for fields named with &#39;_score&#39; at the end.
Examples:
- &#39;HGVS,SIFT,Clinvar&#39; (list of fields)
- &#39;HGVS,*,Clinvar&#39; (list of fields with all other fields at the end)
- &#39;HGVS,.*_score,Clinvar&#39; (list of 2 fields with all scores in the middle)
- &#39;HGVS,.*_score,*&#39; (1 field, scores, all other fields)
- &#39;HGVS,*,.*_score&#39; (1 field, all other fields, all scores)</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="15.4" id="export-3"><span
class="header-section-number">15.4</span> Export</h2>
<p><small></p>
<blockquote>
<pre><code>--include_header

Include header (in VCF format) in output file.
Only for compatible formats (tab-delimiter format as TSV or BED).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--order_by=&lt;order by&gt;

List of columns to sort the result-set in ascending or descending order.
Use SQL format, and keywords ASC (ascending) and DESC (descending).
If a column is not available, order will not be considered.
Order is enable only for compatible format (e.g. TSV, CSV, JSON).
Examples: &#39;ACMG_score DESC&#39;, &#39;PZFlag DESC, PZScore DESC&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--parquet_partitions=&lt;parquet partitions&gt;

Parquet partitioning using hive (available for any format).
This option is faster parallel writing, but memory consuming.
Use &#39;None&#39; (string) for NO partition but split parquet files into a folder.
Examples: &#39;#CHROM&#39;, &#39;#CHROM,REF&#39;, &#39;None&#39;.</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="16" id="minimalize-tool"><span
class="header-section-number">16</span> MINIMALIZE tool</h1>
<p>Minimalize a VCF file consists in put missing value (&#x2018;.&#x2019;) on
INFO/Tags, ID, QUAL or FILTER fields. Options can also minimalize
samples (keep only GT) or remove all samples. INFO/tags can by exploded
before minimalize to keep tags into separated columns (useful for
Parquet or TSV format to constitute a database).</p>
<p>Usage examples:</p>
<blockquote>
<p>howard minimalize &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.minimal.vcf.gz &#x2013;minimalize_info &#x2013;minimalize_filter
&#x2013;minimalize_qual &#x2013;minimalize_id &#x2013;minimalize_samples</p>
</blockquote>
<blockquote>
<p>howard minimalize &#x2013;input=tests/data/example.vcf.gz
&#x2013;output=/tmp/example.minimal.tsv &#x2013;remove_samples &#x2013;explode_infos
&#x2013;minimalize_info</p>
</blockquote>
<blockquote>

</blockquote>
<h2 data-number="16.1" id="main-options-13"><span
class="header-section-number">16.1</span> Main options</h2>
<p><small></p>
<blockquote>
<pre><code>--input=&lt;input&gt; | required

Input file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--output=&lt;output&gt; | required

Output file path.
Format file must be either VCF, Parquet, TSV, CSV, PSV or duckDB.
Files can be compressesd (e.g. vcf.gz, tsv.gz).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--param=&lt;param&gt; (default: {})

Parameters JSON file (or string) defines parameters to process 
annotations, calculations, prioritizations, convertions and queries.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="16.2" id="minimalize"><span
class="header-section-number">16.2</span> Minimalize</h2>
<p><small></p>
<blockquote>
<pre><code>--minimalize_info

Minimalize INFO field (e.g. &#39;.&#39; value).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--minimalize_id

Minimalize ID field (e.g. &#39;.&#39; value).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--minimalize_qual

Minimalize QUAL field (e.g. &#39;.&#39; value).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--minimalize_filter

Minimalize FILTER field (e.g. &#39;.&#39; value).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--minimalize_samples

Minimalize samples to keep only genotypes (i.e. &#39;GT&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--remove_samples

Remove all samples to keep only variants.</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="16.3" id="explode-4"><span
class="header-section-number">16.3</span> Explode</h2>
<p><small></p>
<blockquote>
<pre><code>--explode_infos

Explode VCF INFO/Tag into &#39;variants&#39; table columns.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_prefix=&lt;explode infos prefix&gt;

Explode VCF INFO/Tag with a specific prefix.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--explode_infos_fields=&lt;explode infos list&gt; (default: *)

Explode VCF INFO/Tag specific fields/tags.
Keyword `*` specify all available fields, except those already specified.
Pattern (regex) can be used, such as `.*_score` for fields named with &#39;_score&#39; at the end.
Examples:
- &#39;HGVS,SIFT,Clinvar&#39; (list of fields)
- &#39;HGVS,*,Clinvar&#39; (list of fields with all other fields at the end)
- &#39;HGVS,.*_score,Clinvar&#39; (list of 2 fields with all scores in the middle)
- &#39;HGVS,.*_score,*&#39; (1 field, scores, all other fields)
- &#39;HGVS,*,.*_score&#39; (1 field, all other fields, all scores)</code></pre>
<p></small></p>
</blockquote>
<h2 data-number="16.4" id="export-4"><span
class="header-section-number">16.4</span> Export</h2>
<p><small></p>
<blockquote>
<pre><code>--include_header

Include header (in VCF format) in output file.
Only for compatible formats (tab-delimiter format as TSV or BED).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--order_by=&lt;order by&gt;

List of columns to sort the result-set in ascending or descending order.
Use SQL format, and keywords ASC (ascending) and DESC (descending).
If a column is not available, order will not be considered.
Order is enable only for compatible format (e.g. TSV, CSV, JSON).
Examples: &#39;ACMG_score DESC&#39;, &#39;PZFlag DESC, PZScore DESC&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--parquet_partitions=&lt;parquet partitions&gt;

Parquet partitioning using hive (available for any format).
This option is faster parallel writing, but memory consuming.
Use &#39;None&#39; (string) for NO partition but split parquet files into a folder.
Examples: &#39;#CHROM&#39;, &#39;#CHROM,REF&#39;, &#39;None&#39;.</code></pre>
<p></small></p>
</blockquote>
<h1 data-number="17" id="shared-arguments"><span
class="header-section-number">17</span> Shared arguments</h1>
<p><small></p>
<blockquote>
<pre><code>--config=&lt;config&gt; (default: {})

Configuration JSON file defined default configuration regarding 
resources (e.g. threads, memory),
settings (e.g. verbosity, temporary files),
default folders (e.g. for databases)
and paths to external tools.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--threads=&lt;threads&gt; (default: -1)

Specify the number of threads to use for processing HOWARD.
It determines the level of parallelism,
either on python scripts, duckdb engine and external tools.
It and can help speed up the process/tool.
Use -1 to use all available CPU/cores.
Either non valid value is 1 CPU/core.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--memory=&lt;memory&gt;

Specify the memory to use in format FLOAT[kMG]
(e.g. &#39;8G&#39;, &#39;12.42G&#39;, &#39;1024M&#39;).
It determines the amount of memory for duckDB engine and external tools
(especially for JAR programs).
It can help to prevent &#39;out of memory&#39; failures.
By default (None) is 80%% of RAM (for duckDB).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--chunk_size=&lt;chunk size&gt; (default: 1000000)

Number of records in batch to export output file.
The lower the chunk size, the less memory consumption.
For Parquet partitioning, files size will depend on the chunk size.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--tmp=&lt;Temporary folder&gt;

Temporary folder (e.g. &#39;/tmp&#39;).
By default, &#39;.tmp&#39; for duckDB (see doc),external tools and python scripts.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--duckdb_settings=&lt;duckDB settings&gt;

DuckDB settings (see duckDB doc) as JSON (string or file).
These settings have priority (see options &#39;threads&#39;, &#39;tmp&#39;...).
Examples: &#39;{&quot;TimeZone&quot;: &quot;GMT&quot;, &quot;temp_directory&quot;: &quot;/tmp/duckdb&quot;, &quot;threads&quot;: 8}&#39;.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--verbosity=&lt;verbosity&gt; [&#39;CRITICAL&#39;, &#39;ERROR&#39;, &#39;WARNING&#39;, &#39;INFO&#39;, &#39;DEBUG&#39;, &#39;NOTSET&#39;] (default: INFO)

Verbosity level
Available: CRITICAL, ERROR, WARNING, INFO, DEBUG or NOTSET
- DEBUG: Detailed information, typically of interest only when diagnosing problems.
- INFO: Confirmation that things are working as expected.
- WARNING: An indication that something unexpected happened.
- ERROR: Due to a more serious problem.
- CRITICAL: A serious error.
- NOTSET: All messages.</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--log=&lt;log&gt;

Logs file
(e.g. &#39;my.log&#39;).</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--quiet

==SUPPRESS==</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--verbose

==SUPPRESS==</code></pre>
<p></small></p>
</blockquote>
<p><small></p>
<blockquote>
<pre><code>--debug

==SUPPRESS==</code></pre>
<p></small></p>
</blockquote>
</body>
</html>
